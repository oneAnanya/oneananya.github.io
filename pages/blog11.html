<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Solving LRU Cache Problem in Java">
    <meta name="author" content="Your Name">
    <title>Solving LRU Cache Problem in Java</title>
    <link rel="stylesheet" type="text/css" media="screen" href="../styles/main.css">
    <link rel="icon" type="image/x-icon" href="../assets/images/favicon.ico">
    <style>
        body {
            font-family: "Comic Sans MS", cursive, sans-serif;
            line-height: 1.6;
            padding: 20px;
        }
        h2 {
            color: #D8BFD8; /* Baby purple color */
            font-size: 24px;
            margin-bottom: 10px;
        }
        p {
            margin-bottom: 15px;
        }
        .content-wrapper {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(255, 255, 255, 0.603);
        }
        .section-page {
            margin-bottom: 20px;
        }
        .flowchart {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .flowchart div {
            display: flex;
            align-items: center;
            justify-content: center;
            border: 1px solid #D8BFD8;;
            padding: 10px;
            margin: 5px;
            border-radius: 5px;
        }
        .oval {
            border-radius: 50%;
            width: 100px;
            height: 50px;
            text-align: center;
        }
        .parallelogram {
            width: 150px;
            height: 50px;
            transform: skewX(-20deg);
            text-align: center;
        }
        .rectangle-rounded {
            border-radius: 10px;
            width: 200px;
            height: 50px;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="content-wrapper">
        <section class="section-page">
            <h2>Solving LRU Cache Problem in Java</h2>
            <p>The Least Recently Used (LRU) cache algorithm is designed to remove the least recently accessed item from the cache to make space for new items when the cache is full.</p>
            <p>We can solve this problem using a combination of a HashMap and a Doubly Linked List:</p>
            <p>1. The HashMap provides O(1) access time for the cache items.</p>
            <p>2. The Doubly Linked List maintains the order of items based on their access time, with the most recently accessed item at the front and the least recently accessed item at the back.</p>

            <h2>Flowchart:</h2>
            <div class="flowchart">
                <div class="oval">Start</div>
                <div class="rectangle-rounded">Initialize HashMap and Doubly Linked List</div>
                <div class="parallelogram">Cache Access</div>
                <div class="rectangle-rounded">Update Access Order</div>
                <div class="rectangle-rounded">Add/Remove Items as Necessary</div>
                <div class="oval">End</div>
            </div>

            <h2>Shape Names:</h2>
            <p>1. Start/End: Oval</p>
            <p>2. Initialize HashMap and Doubly Linked List: Rectangle with rounded corners</p>
            <p>3. Cache Access: Parallelogram</p>
            <p>4. Update Access Order: Rectangle with rounded corners</p>
            <p>5. Add/Remove Items as Necessary: Rectangle with rounded corners</p>

            <h2>Pseudocode:</h2>
            <p>Start</p>
            <p>Initialize a HashMap and a Doubly Linked List</p>
            <p>For each cache access:</p>
            <p>&nbsp;&nbsp;&nbsp;If the item is in the cache, move it to the front of the list</p>
            <p>&nbsp;&nbsp;&nbsp;If the item is not in the cache, add it to the front of the list and update the HashMap</p>
            <p>&nbsp;&nbsp;&nbsp;If the cache is full, remove the item at the back of the list and update the HashMap</p>
            <p>End</p>

            <h2>Algorithm:</h2>
            <p>1. Initialize a HashMap and a Doubly Linked List.</p>
            <p>2. For each cache access:</p>
            <p>&nbsp;&nbsp;&nbsp;a. If the item is in the cache, move it to the front of the list.</p>
            <p>&nbsp;&nbsp;&nbsp;b. If the item is not in the cache, add it to the front of the list and update the HashMap.</p>
            <p>&nbsp;&nbsp;&nbsp;c. If the cache is full, remove the item at the back of the list and update the HashMap.</p>

            <h2>DFD-0:</h2>
            <div class="flowchart">
                <div class="oval">Start</div>
                <div class="rectangle-rounded">Initialize HashMap and Doubly Linked List</div>
                <div class="parallelogram">Cache Access</div>
                <div class="rectangle-rounded">Update Access Order</div>
                <div class="rectangle-rounded">Add/Remove Items as Necessary</div>
                <div class="oval">End</div>
            </div>

            <h2>DFD-1:</h2>
            <div class="flowchart">
                <div class="rectangle-rounded">Initialize HashMap and Doubly Linked List</div>
                <div class="parallelogram">Cache Access</div>
                <div class="rectangle-rounded">Check if Item is in Cache</div>
                <div class="rectangle">Move to Front if in Cache</div>
                <div class="rectangle">Add to Front if not in Cache</div>
                <div class="rectangle-rounded">Remove LRU Item if Cache is Full</div>
            </div>

            <h2>Java Implementation:</h2>
            <pre><code>
import java.util.*;

class LRUCache 
{
    private final int capacity;
    private final Map<Integer, Integer> cache;
    private final LinkedList<Integer> order;

    public LRUCache(int capacity) 
    {
        this.capacity = capacity;
        this.cache = new HashMap<>();
        this.order = new LinkedList<>();
    }

    public int get(int key) 
    {
        if (!cache.containsKey(key)) 
        {
            return -1;
        }
        order.remove((Integer) key);
        order.addFirst(key);
        return cache.get(key);
    }

    public void put(int key, int value) 
    {
        if (cache.containsKey(key)) 
        {
            order.remove((Integer) key);
        } 
        else if (cache.size() == capacity) 
        {
            int oldest = order.removeLast();
            cache.remove(oldest);
        }
        order.addFirst(key);
        cache.put(key, value);
    }
}

//execution:
public class Main 
{
    public static void main(String[] args) 
    {
        LRUCache lruCache = new LRUCache(2);
        lruCache.put(1, 1);
        lruCache.put(2, 2);
        System.out.println(lruCache.get(1)); // returns 1
        lruCache.put(3, 3); // evicts key 2
        System.out.println(lruCache.get(2)); // returns -1 (not found)
        lruCache.put(4, 4); // evicts key 1
        System.out.println(lruCache.get(1)); // returns -1 (not found)
        System.out.println(lruCache.get(3)); // returns 3
        System.out.println(lruCache.get(4)); // returns 4
    }
}
            </code></pre>

            <h2>Use Case:</h2>
            <p>- User initiates cache access.</p>
            <p>- The program starts with initializing a HashMap and a Doubly Linked List.</p>
            <p>- For each cache access, the program checks if the item is in the cache.</p>
            <p>- If the item is in the cache, it moves the item to the front of the list.</p>
            <p>- If the item is not in the cache, it adds the item to the front of the list and updates the HashMap.</p>
            <p>- If the cache is full, it removes the item at the back of the list and updates the HashMap.</p>
            <p>- The updated cache is displayed to the user.</p>

            <h2>SDLC 7 Stages:</h2>
            <p>1. Planning: Define the need and purpose of implementing the LRU cache algorithm.</p>
            <p>2. Analysis: Examine the requirements and determine the approach for implementing the LRU cache.</p>
            <p>3. Design: Create the flowchart, pseudocode, algorithm, DFDs, and use case.</p>
            <p>4. Implementation: Implement the LRU cache algorithm in Java.</p>
            <p>5. Testing: Verify the functionality of the LRU cache with various test cases.</p>
            <p>6. Deployment: Deploy the LRU cache implementation for users.</p>
            <p>7. Maintenance: Maintain and optimize the LRU cache implementation as needed.</p>
        </section>
    </div>
</body>
</html>
